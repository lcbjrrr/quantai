{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDhAPsOHy/9ZjaRw/5MeUh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcbjrrr/quantai/blob/main/02_FIAP_Ext_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforcement Learning (Intro)"
      ],
      "metadata": {
        "id": "nWr4s29geLud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinforcement learning is a type of machine learning where an agent learns to make better decisions through trial and error. In this setup, the *agent* acts as the learner or decision maker, while the *environment* represents everything the agent interacts with. As the agent explores the environment, it observes the current *state*â€”a snapshot of the situationâ€”and selects an *action* in response. The environment then returns a new state and provides a *reward*, which signals how good or bad the action was. Over time, the agent uses these rewards to improve its decision-making and discover strategies that lead to better outcomes. Think of it like training a robot to ride an elevator: every time it presses the right button and reaches the desired floor, it earns a reward and learns to repeat that success."
      ],
      "metadata": {
        "id": "KzLFFkUdSDCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/1*suRqGq0gWXQV2bcMGAhA_A.jpeg)"
      ],
      "metadata": {
        "id": "cCFG9FtIYp4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.state = 0\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        reward = self.calc_reward(action)\n",
        "        self.state = self.state + reward\n",
        "        # Takes an action and returns (next_state, reward, done)\n",
        "        if self.state == 3:\n",
        "          return (self.state, reward, True)\n",
        "        else:\n",
        "          return (self.state, reward, False)\n",
        "\n",
        "    def calc_reward(self, action):\n",
        "        if action == \"R\":   # (R)ight\n",
        "            return 1        # Reward of 1\n",
        "        elif action == \"L\": # (L)eft\n",
        "            return -1       # Penalty of -1\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.actions = [\"L\", \"R\"]\n",
        "\n",
        "    def choose_action(self):\n",
        "        return random.choice(self.actions)\n",
        ""
      ],
      "metadata": {
        "id": "6cQ_htQXSDH9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "done = False\n",
        "steps = 0\n",
        "\n",
        "while not done and steps < 30:\n",
        "    state = env.get_state()\n",
        "    action = agent.choose_action()\n",
        "    next_state, reward, done = env.step(action)\n",
        "\n",
        "    print(f\"Step {steps}: State={state}, Action={action}, Next State={next_state}, Reward={reward}\")\n",
        "    steps += 1\n",
        "\n",
        "if done:\n",
        "    print(\"ðŸŽ‰ Agent reached the goal!\")\n",
        "else:\n",
        "    print(\"âŒ Agent did not reach the goal in time.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU8bPwdcbbQk",
        "outputId": "e869692a-afa9-4518-b1e7-a3db171c1260"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: State=0, Action=L, Next State=-1, Reward=-1\n",
            "Step 1: State=-1, Action=R, Next State=0, Reward=1\n",
            "Step 2: State=0, Action=R, Next State=1, Reward=1\n",
            "Step 3: State=1, Action=L, Next State=0, Reward=-1\n",
            "Step 4: State=0, Action=L, Next State=-1, Reward=-1\n",
            "Step 5: State=-1, Action=L, Next State=-2, Reward=-1\n",
            "Step 6: State=-2, Action=R, Next State=-1, Reward=1\n",
            "Step 7: State=-1, Action=R, Next State=0, Reward=1\n",
            "Step 8: State=0, Action=R, Next State=1, Reward=1\n",
            "Step 9: State=1, Action=R, Next State=2, Reward=1\n",
            "Step 10: State=2, Action=R, Next State=3, Reward=1\n",
            "ðŸŽ‰ Agent reached the goal!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ativity: Elevator"
      ],
      "metadata": {
        "id": "yRTvNmB0d4tj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design a reinforcement learning solution where an agent simulates a person trying to reach a desired floor using an elevator. The user will input three values: the number of floors in the building, the starting floor, and the target floor. The agent can choose to move either â€œupâ€ or â€œdown,â€ and the episode continues until the agent arrives at the destination. Reaching the target floor yields a reward of +1, while all other movements result in a reward of 0. The agent should learn to navigate efficiently, avoiding invalid moves beyond the building limits, and use the environmentâ€™s feedback to reach the goal. Students are expected to implement an environment and agent class, define the decision logic, and simulate the episode with this setup."
      ],
      "metadata": {
        "id": "8y7d13Nld6w5"
      }
    }
  ]
}